{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "5-f8-Il-O2o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary libraries"
      ],
      "metadata": {
        "id": "iM9-CcQqNJeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epk0MLqrOMbQ"
      },
      "outputs": [],
      "source": [
        "! pip install langchain_community  langchain\n",
        "! pip install -qU langchain-huggingface sentence_transformers  langchain-qdrant qdrant_client fastembed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing"
      ],
      "metadata": {
        "id": "xue1q_JwNTRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Define list of URLs"
      ],
      "metadata": {
        "id": "CJXBK2WeNA6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    # RAG\n",
        "    \"https://www.digitalocean.com/community/conceptual-articles/rag-ai-agents-agentic-rag-comparative-analysis\",\n",
        "    \"https://medium.com/@tejpal.abhyuday/retrieval-augmented-generation-rag-from-basics-to-advanced-a2b068fd576c\",\n",
        "    \"https://orkes.io/blog/rag-best-practices/\",\n",
        "    \"https://medium.com/@airtonlirajr/langchain-rag-retrieval-augmented-generation-edc34451c7c6\",\n",
        "    \"https://pub.towardsai.net/langchain-101-part-1-building-simple-q-a-app-90d9c4e815f3\",\n",
        "    \"https://medium.com/@prasadmahamulkar/introduction-to-retrieval-augmented-generation-rag-using-langchain-and-lamaindex-bd0047628e2a\",\n",
        "    \"https://jayant017.medium.com/rag-using-langchain-part-3-vector-stores-and-retrievers-a75f4d14cbf3\",\n",
        "    \"https://pub.towardsai.net/langchain-101-part-3a-talking-to-documents-load-split-and-simple-rag-with-lcel-26b005ccb30a\",\n",
        "    \"https://pub.towardsai.net/langchain-101-part-3b-talking-to-documents-embeddings-and-vectorstores-c37d460f1519\",\n",
        "    # RAG evaluation\n",
        "    \"https://medium.com/data-science/evaluating-rag-applications-with-ragas-81d67b0ee31a\",\n",
        "    \"https://medium.com/@rupeshyadav153/evaluation-of-retrieval-augmented-generation-rag-using-ragas-on-human-annotated-and-synthetic-09c4b825c298\",\n",
        "    \"https://medium.com/@mauryaanoop3/rag-evaluation-using-ragas-a-comprehensive-guide-05bf439137c5\",\n",
        "    # LLM evaluation\n",
        "    \"https://amagastya.medium.com/decoding-llm-performance-a-guide-to-evaluating-llm-applications-e8d7939cafce\",\n",
        "    \"https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5\",\n",
        "    # Agents\n",
        "    \"https://medium.com/@jagadeesan.ganesh/mastering-llm-ai-agents-building-and-using-ai-agents-in-python-with-real-world-use-cases-c578eb640e35\",\n",
        "    \"https://medium.com/@vinusebastianthomas/langchain-agents-unleashing-the-power-of-language-models-for-real-world-automation-d4a75845717f\",\n",
        "    \"https://medium.com/@has.dhia/generative-agent-simulations-of-1-000-people-873b0e1761d8\",\n",
        "    \"https://blog.langchain.dev/langgraph-multi-agent-workflows/\",\n",
        "    \"https://www.getzep.com/ai-agents/langchain-agents-langgraph\",\n",
        "    \"https://www.ibm.com/think/topics/langgraph\",\n",
        "    \"https://www.promptingguide.ai/research/llm-agents\",\n",
        "    \"https://botpress.com/blog/llm-agents\",\n",
        "    \"https://onagents.org/patterns/\",\n",
        "    \"https://oxylabs.io/blog/best-ai-agent-frameworks\",\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    # Prompt engineering\n",
        "    \"https://medium.com/@fareedkhandev/prompt-engineering-complete-guide-2968776f0431\",\n",
        "    \"https://medium.com/@pankaj_pandey/chain-of-thought-prompting-guiding-llms-step-by-step-e6eac32d02d8\",\n",
        "    \"https://medium.com/@WeavePlatform/unleashing-the-power-of-chain-of-thought-prompting-8d09e1f08fe2\",\n",
        "    \"https://community.aws/content/2wzRXcEcE7u3LfukKwiYIf75Rpw/how-to-get-structured-output-from-llm-s-a-practical-guide\",\n",
        "    \"https://neptune.ai/blog/llm-for-structured-data\",\n",
        "    # Fine-tuning\n",
        "    \"https://dassum.medium.com/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07\",\n",
        "    \"https://medium.com/@amit25173/langchain-fine-tuning-bc34c9c8ecf7\",\n",
        "    \"https://medium.com/@dataoilst.info/fine-tuning-langchain-llm-applications-a-technical-perspective-part-1-4b4c552ab557\",\n",
        "    \"https://medium.com/@noel.B/decoding-langchains-structured-llm-calls-for-model-fine-tuning-eaea34710783\",\n",
        "    \"https://pub.towardsai.net/langchain-101-part-2ab-all-you-need-to-know-about-large-language-models-3512ae41dfc3\",\n",
        "    \"https://medium.com/towards-artificial-intelligence/langchain-101-part-2d-fine-tuning-llms-with-human-feedback-57769479d013\",\n",
        "    \"https://medium.com/towards-artificial-intelligence/langchain-101-part-2c-fine-tuning-llms-with-peft-lora-and-rl-5c9890ed0766\",\n",
        "    \"https://medium.com/@fasihahmad44/a-comprehensive-guide-on-fine-tuning-llms-be99c89a97a0\",\n",
        "    \"https://medium.com/@cs.ahmetyusufalan/how-to-fine-tune-private-llm-without-1300-908cf229a702\",\n",
        "    \"https://anirbansen2709.medium.com/finetuning-llms-using-lora-77fb02cbbc48\",\n",
        "    \"https://www.datacamp.com/tutorial/fine-tuning-large-language-models\",\n",
        "    \"https://huggingface.co/blog/lora\",\n",
        "    # NLP & Longformer\n",
        "    \"https://www.datacamp.com/blog/what-is-natural-language-processing\",\n",
        "    \"https://www.geeksforgeeks.org/advanced-topics-in-natural-language-processing/\",\n",
        "    \"https://www.ibm.com/cloud/learn/natural-language-processing\",\n",
        "    \"https://builtin.com/artificial-intelligence/transformer-neural-network\",\n",
        "    \"https://aiml.com/explain-the-transformer-architecture/\",\n",
        "    \"https://jalammar.github.io/illustrated-transformer/\",\n",
        "    \"https://julius.ai/glossary/transformer-deep-learning-architecture\",\n",
        "    \"https://pub.towardsai.net/how-does-an-llm-generate-text-fd9c57781217\",\n",
        "    \"https://pub.towardsai.net/how-to-fit-large-language-models-in-small-memory-quantization-e8c3981430b2\",\n",
        "    # Vector DBs & Chroma/FAISS\n",
        "    \"https://medium.com/@EjiroOnose/vector-database-what-is-it-and-why-you-should-know-it-ae7e7dca82a4\",\n",
        "    \"https://medium.com/@tahirbalarabe2/what-are-vector-databases-the-secret-sauce-behind-ai-and-llms-62ff320a6843\",\n",
        "    \"https://medium.com/@AndresHerranz/llms-langchain-and-vectorstores-2489a2ea1ef1\",\n",
        "    \"https://medium.com/munchy-bytes/exploring-langchain-ff13fff63340\",\n",
        "    # Hallucination mitigation\n",
        "    \"https://medium.com/@tselvaraj/effective-methods-to-mitigate-hallucinations-in-large-language-models-llms-f72f5a402889\",\n",
        "    \"https://medium.com/low-code-for-advanced-data-science/what-are-ai-hallucinations-how-to-mitigate-them-in-llms-4abf0cd54a7a\",\n",
        "    \"https://cobusgreyling.medium.com/large-language-model-hallucination-mitigation-techniques-a75b6f873318\",\n",
        "    # Guardrails & safety\n",
        "    \"https://medium.com/data-science/safeguarding-llms-with-guardrails-4f5d9f57cff2\",\n",
        "    \"https://medium.com/@sls007/llm-guardrails-a-comprehensive-guide-to-securing-ai-applications-9ded5789da16\",\n",
        "    \"https://ssahuupgrad-93226.medium.com/llm-guardrails-f025e5d8111b\",\n",
        "    # Knowledge Graphs + RAG\n",
        "    \"https://medium.com/@manikantan.srinivasan2001/enhancing-llms-with-knowledge-graphs-and-rag-a-definitive-guide-b6716cd05320\",\n",
        "    \"https://medium.com/data-science/building-knowledge-graphs-with-llm-graph-transformer-a91045c49b59\",\n",
        "    \"https://medium.com/data-science/enterprise-ready-knowledge-graphs-96028d863e8c\",\n",
        "    # Memory in LangChain\n",
        "    \"https://medium.com/@danushidk507/memory-in-langchain-1-56fda38ba1d7\",\n",
        "    \"https://medium.com/bosphorusiss/part-1-4-langchain-memory-4ce20d5529a8\",\n",
        "    \"https://medium.com/@rahulpant.me/langchain-memory-types-in-simple-words-9fc142003567\",\n",
        "    # ─── Added RL-based reasoning ───\n",
        "    \"https://sebastianraschka.com/blog/2025/the-state-of-reinforcement-learning-for-llm-reasoning.html\",\n",
        "    \"https://www.promptingguide.ai/techniques/cot\",\n",
        "    \"https://aws.amazon.com/what-is/reinforcement-learning-from-human-feedback/\",\n",
        "    \"https://datasciencedojo.com/blog/rlhf-and-dpo-for-finetuning-llms/\",\n",
        "    \"https://kargarisaac.medium.com/how-deepseek-r1-uses-reinforcement-learningto-supercharge-reasoning-3f826c2c8759\",\n",
        "    \"https://medium.com/the-ai-technology/rlhf-for-llms-a-deep-dive-into-reinforcement-learning-from-human-feedback-98637a1e38f2\",\n",
        "    \"https://medium.com/@tahirbalarabe2/deepseek-r1-explained-chain-of-thought-reinforcement-learning-and-model-distillation-0eb165d928c9\",\n",
        "    # Perfecting LLMs via RLHF\n",
        "    \"https://medium.com/https-towardsdatascience-com/perfecting-llms-to-mirror-human-preferences-accurately-through-rlhf-c7023ded7511\",\n",
        "    \"https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback\",\n",
        "    # ─── LangGraph ───\n",
        "    \"https://medium.com/@cplog/building-tool-calling-conversational-ai-with-langchain-and-langgraph-a-beginners-guide-8d6986cc589e\",\n",
        "    \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\",\n",
        "    # ─── Model Context Protocol (MCP) ───\n",
        "    \"https://cobusgreyling.medium.com/using-langchain-with-model-context-protocol-mcp-e89b87ee3c4c\",\n",
        "    \"https://medium.com/@sulbha.jindal/langchain-vs-model-context-protocol-mcp-from-anthropic-c46aa53193e5\",\n",
        "    \"https://en.wikipedia.org/wiki/Model_Context_Protocol\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "ufY97KbMW-Xq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-MNeQR3XAEx",
        "outputId": "c616c0df-0a0d-4dd4-d38a-b0603cead2ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Load page content of each website"
      ],
      "metadata": {
        "id": "mKIPdEZLXkZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Load Documents\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=urls,\n",
        "\n",
        ")\n",
        "\n",
        "docs = loader.load()\n"
      ],
      "metadata": {
        "id": "7o-VNWroXBR1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVkbr-Q3XYWw",
        "outputId": "0e73ce88-9e8c-40e0-aa7a-e5136519e2dd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Use a Text Splitter to Split Documents into chunks"
      ],
      "metadata": {
        "id": "P-TxB_69X4lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=50)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "g66xvVFUh0N0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Embed the documents and store them"
      ],
      "metadata": {
        "id": "xBj6wI8KYRJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load embedding model from Hugging Face"
      ],
      "metadata": {
        "id": "nSClfiwhYWVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "#sentence-transformers/all-MiniLM-L6-v2\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    multi_process=True,\n",
        "    model_kwargs={\"device\": \"cpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
        "\n",
        ")\n",
        "print(f\"Model's maximum sequence length: {SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2').max_seq_length}\")"
      ],
      "metadata": {
        "id": "pKaioYWyh5EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to vector store locally or in cloud"
      ],
      "metadata": {
        "id": "YvCqqNKOYbBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_qdrant import FastEmbedSparse,QdrantVectorStore,RetrievalMode\n",
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.http.models import Distance, SparseVectorParams, VectorParams\n",
        "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
        "\n",
        "client = QdrantClient(\n",
        "    #path=\"/content/vector_store_folder\"\n",
        "    #\":memory:\"\n",
        "    # you can use :memory: mode for fast and light-weight experiments,\n",
        "    # set API KEY for Qdrant Cloud\n",
        "    # url=\"https://dc1c0e76-26f0-49d1-9417-dad988d7c889.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    # api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.PDwp-zTytGwneuGTuePZ3LFjbKQAr-YuilwscMZbCIU\",\n",
        "    url=\"https://e7739953-b688-421a-837b-6016c3420745.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.6d9Vx1zhq7qdPUJtjUgWaMOI_c-39UTymTofltIWbus\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "7I01mtTqkm6d"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create collection if there is not any already (config for hybrid search)"
      ],
      "metadata": {
        "id": "JBvlE85lZEKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"workshop_collection\",\n",
        "    vectors_config={\"dense\": VectorParams(size=384, distance=Distance.COSINE)},\n",
        "    sparse_vectors_config={\n",
        "        \"sparse\": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))\n",
        "    },\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "2CSeyfgaY-JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config vector store instance to your collection and add the embedded documents"
      ],
      "metadata": {
        "id": "lG632fHlZM7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"workshop_collection\",\n",
        "    embedding=embedding_model,\n",
        "    sparse_embedding=sparse_embeddings,\n",
        "    retrieval_mode=RetrievalMode.HYBRID,\n",
        "    vector_name=\"dense\",\n",
        "    sparse_vector_name=\"sparse\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "MQ7JNdIrY_QN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.add_documents(documents=splits)"
      ],
      "metadata": {
        "id": "nT9XG2Q9ZpA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test the retriever"
      ],
      "metadata": {
        "id": "8auWoNGkZZCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"What are typical Agent Patterns\"\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 15})\n",
        "docs = retriever.get_relevant_documents(user_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNUdz1B8HB0D",
        "outputId": "314bdefe-5f8c-4e38-9a63-66dc4d39695c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-b710e96d6dba>:3: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(user_query)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "UWhTDqn7aNYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmysa7dmaBBJ",
        "outputId": "c7ccd330-43fc-478e-a4b6-91afa1fc9889"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential flow patterns organize agents in a predefined linear sequence, like an assembly line. Each agent’s output becomes input for the next, creating a clear chain of responsibility. This pattern excels in straightforward, step-by-step processes but\n"
          ]
        }
      ]
    }
  ]
}